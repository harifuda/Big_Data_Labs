{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690a4098-775f-4de5-8aac-6a2ba9f1b866",
   "metadata": {},
   "source": [
    "# FlatMap ReduceByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b348adba-cd6f-479f-8529-a14689a8ca0d",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to learn two new features of PySpark, FlatMap and ReduceByKey\n",
    "\n",
    "At the beginning of this session, you have to create a new session to work with this section of the tutorial. Another section of this tutorial is to run our popular Spark Program (Word Count in a document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e48530-fd54-47cd-a875-94646e13877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession.builder.master(\"local\").appName(\"FlatMap-ReduceByKey\").getOrCreate();\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a677d8-58a1-4635-b90c-a71a91a7b1c4",
   "metadata": {},
   "source": [
    "\n",
    "## ReduceByKey()\n",
    "\n",
    "ReduceByKey function operates on key,value pairs. The function will merge the data elements with the same key value, and will reduce them based on a lambda that we pass. \n",
    "\n",
    "**Note that reduceByKey is not an action function like reduce. This is a transformation function. Which means the data will not be processed when we use it until an action is being used**\n",
    "\n",
    "### Syntax\n",
    "reduceByKey(condition with expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833dc258-e9d5-496f-a0fc-093c381fc772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 1), (2, 1), (3, 1), (1, 1), (5, 1), (2, 1), (3, 1), (1, 1), (4, 1), (2, 1), (4, 1), (1, 1), (5, 1), (6, 1), (12, 1)]\n"
     ]
    }
   ],
   "source": [
    "# From Previous Examples\n",
    "\n",
    "rdd = sc.parallelize([1,2,2,3,1,5,2,3,1,4,2,4,1,5,6,12])\n",
    "rdd = rdd.map(lambda x: (x, 1))\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601ab8bf-69b4-4e57-9386-7caead3e77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 4), (3, 2), (5, 2), (4, 2), (6, 1), (12, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can reduce by the key and add the values that has the key matching\n",
    "rdd = rdd.reduceByKey(lambda x,y: x+y)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a409c-c7b7-4e64-a3d8-d6e544a62167",
   "metadata": {},
   "source": [
    "You see!!! now we have a reduced mapped values over here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf65d43-d50a-4292-93ef-ecb72ece6c2f",
   "metadata": {},
   "source": [
    "\n",
    "## FlatMap\n",
    "PySpark flatMap() is a transformation operation that flattens the RDD/DataFrame (array/map DataFrame columns) after applying the function on every element and returns a new PySpark RDD/DataFrame.\n",
    "\n",
    "In one of the previous exercises, we processed array of strings and then we split that string. The returned object was an array that contained all the values of the string split. \n",
    "\n",
    "If we want to count the occurances of words in these sentences, we can try something similar.\n",
    "\n",
    "Let's create a sample data first. We will do the map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45df4c39-2fb3-4758-a238-003e79cdd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"word count from Wikipedia the free encyclopedia\",\n",
    "    \"the word count is the number of words in a document or passage of text Word counting may be needed when a text\",\n",
    "    \"is required to stay within certain numbers of words This may particularly be the case in academia legal\",\n",
    "    \"proceedings journalism and advertising Word count is commonly used by translators to determine the price for\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc69cf2-a082-4008-b6c8-d499a0b87a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['word', 'count', 'from', 'Wikipedia', 'the', 'free', 'encyclopedia'],\n",
       " ['the',\n",
       "  'word',\n",
       "  'count',\n",
       "  'is',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'words',\n",
       "  'in',\n",
       "  'a',\n",
       "  'document',\n",
       "  'or',\n",
       "  'passage',\n",
       "  'of',\n",
       "  'text',\n",
       "  'Word',\n",
       "  'counting',\n",
       "  'may',\n",
       "  'be',\n",
       "  'needed',\n",
       "  'when',\n",
       "  'a',\n",
       "  'text'],\n",
       " ['is',\n",
       "  'required',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'within',\n",
       "  'certain',\n",
       "  'numbers',\n",
       "  'of',\n",
       "  'words',\n",
       "  'This',\n",
       "  'may',\n",
       "  'particularly',\n",
       "  'be',\n",
       "  'the',\n",
       "  'case',\n",
       "  'in',\n",
       "  'academia',\n",
       "  'legal'],\n",
       " ['proceedings',\n",
       "  'journalism',\n",
       "  'and',\n",
       "  'advertising',\n",
       "  'Word',\n",
       "  'count',\n",
       "  'is',\n",
       "  'commonly',\n",
       "  'used',\n",
       "  'by',\n",
       "  'translators',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'price',\n",
       "  'for']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRdd = sc.parallelize(lines).map(lambda x: x.split(\" \")) #we are splitting on the space\n",
    "wordsRdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3660086-e1f1-402e-ba28-a9a054070acd",
   "metadata": {},
   "source": [
    "**Our data is basically an array of words for every element that is representing the line! But this is not what we want. We want every word to be a separate element. So that we can use the word itself as a key and count the occurances.**\n",
    "\n",
    "As we discussed above. FlatMap is a transofrmation function that will flatten the collection element (array for example) and makes every element in the array an element in the RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be89238a-2543-45ff-8238-15e8c393a558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word',\n",
       " 'count',\n",
       " 'from',\n",
       " 'Wikipedia',\n",
       " 'the',\n",
       " 'free',\n",
       " 'encyclopedia',\n",
       " 'the',\n",
       " 'word',\n",
       " 'count',\n",
       " 'is',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'words',\n",
       " 'in',\n",
       " 'a',\n",
       " 'document',\n",
       " 'or',\n",
       " 'passage',\n",
       " 'of',\n",
       " 'text',\n",
       " 'Word',\n",
       " 'counting',\n",
       " 'may',\n",
       " 'be',\n",
       " 'needed',\n",
       " 'when',\n",
       " 'a',\n",
       " 'text',\n",
       " 'is',\n",
       " 'required',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'within',\n",
       " 'certain',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'words',\n",
       " 'This',\n",
       " 'may',\n",
       " 'particularly',\n",
       " 'be',\n",
       " 'the',\n",
       " 'case',\n",
       " 'in',\n",
       " 'academia',\n",
       " 'legal',\n",
       " 'proceedings',\n",
       " 'journalism',\n",
       " 'and',\n",
       " 'advertising',\n",
       " 'Word',\n",
       " 'count',\n",
       " 'is',\n",
       " 'commonly',\n",
       " 'used',\n",
       " 'by',\n",
       " 'translators',\n",
       " 'to',\n",
       " 'determine',\n",
       " 'the',\n",
       " 'price',\n",
       " 'for']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example witll run using FlatMap\n",
    "\n",
    "wordsRdd = sc.parallelize(lines).flatMap(lambda x: x.split(\" \")) #we are splitting on the space\n",
    "wordsRdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa60727-389f-4d3d-b880-1341c800463b",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Did you see any difference? What is that? Explain..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4625c-0f33-49a8-b53f-3a95359c2c22",
   "metadata": {},
   "source": [
    ".map() divivdes each string and stores the output as lists, resulting in a nested array with a length of 4.\n",
    "\n",
    ".flatMap() simply divides each element and stores the output in one list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844c06d-41a5-4a44-8277-07f150822dea",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The following is the same data used in the previous notebook that represents houses with the following columns:\n",
    "\"Sell\", \"List\", \"Living\", \"Rooms\", \"Beds\", \"Baths\", \"Age\", \"Acres\", \"Taxes\"\n",
    "\n",
    "Find the sum of all taxes paid per number of beds in the hourse. For example for all the houses with 4 beds the total taxes paid is X. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023792bd-fce5-4b72-b776-8fce2142b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Data\n",
    "\n",
    "data = [\n",
    "\"142, 160, 28, 10, 5, 3, 60, 0.28, 3167\",\n",
    "\"175, 180, 18, 8, 4, 1, 12, 0.43, 4033\",\n",
    "\"129, 132, 13, 6, 3, 1, 41, 0.33, 1471\",\n",
    "\"138, 140, 17, 7, 3, 1, 22, 0.46, 3204\",\n",
    "\"232, 240, 25, 8, 4, 3, 5, 2.05, 3613\",\n",
    "\"135, 140, 18, 7, 4, 3, 9, 0.57, 3028\",\n",
    "\"150, 160, 20, 8, 4, 3, 18, 4.00, 3131\",\n",
    "\"207, 225, 22, 8, 4, 2, 16, 2.22, 5158\",\n",
    "\"271, 285, 30, 10, 5, 2, 30, 0.53, 5702\",\n",
    "\"89,  90, 10, 5, 3, 1, 43, 0.30, 2054\",\n",
    "\"153, 157, 22, 8, 3, 3, 18, 0.38, 4127\",\n",
    "\"87,  90, 16, 7, 3, 1, 50, 0.65, 1445\",\n",
    "\"234, 238, 25, 8, 4, 2, 2, 1.61, 2087\",\n",
    "\"106, 116, 20, 8, 4, 1, 13, 0.22, 2818\",\n",
    "\"175, 180, 22, 8, 4, 2, 15, 2.06, 3917\",\n",
    "\"165, 170, 17, 8, 4, 2, 33, 0.46, 2220\",\n",
    "\"166, 170, 23, 9, 4, 2, 37, 0.27, 3498\",\n",
    "\"136, 140, 19, 7, 3, 1, 22, 0.63, 3607\",\n",
    "\"148, 160, 17, 7, 3, 2, 13, 0.36, 3648\",\n",
    "\"151, 153, 19, 8, 4, 2, 24, 0.34, 3561\",\n",
    "\"180, 190, 24, 9, 4, 2, 10, 1.55, 4681\",\n",
    "\"293, 305, 26, 8, 4, 3, 6, 0.46, 7088\",\n",
    "\"167, 170, 20, 9, 4, 2, 46, 0.46, 3482\",\n",
    "\"190, 193, 22, 9, 5, 2, 37, 0.48, 3920\",\n",
    "\"184, 190, 21, 9, 5, 2, 27, 1.30, 4162\",\n",
    "\"157, 165, 20, 8, 4, 2, 7, 0.30, 3785\",\n",
    "\"110, 115, 16, 8, 4, 1, 26, 0.29, 3103\",\n",
    "\"135, 145, 18, 7, 4, 1, 35, 0.43, 3363\",\n",
    "\"567, 625, 64, 11, 4, 4, 4, 0.85, 12192\",\n",
    "\"180, 185, 20, 8, 4, 2, 11, 1.00, 3831\",\n",
    "\"183, 188, 17, 7, 3, 2, 16, 3.00, 3564\",\n",
    "\"185, 193, 20, 9, 3, 2, 56, 6.49, 3765\",\n",
    "\"152, 155, 17, 8, 4, 1, 33, 0.70, 3361\",\n",
    "\"148, 153, 13, 6, 3, 2, 22, 0.39, 3950\",\n",
    "\"152, 159, 15, 7, 3, 1, 25, 0.59, 3055\",\n",
    "\"146, 150, 16, 7, 3, 1, 31, 0.36, 2950\",\n",
    "\"170, 190, 24, 10, 3, 2, 33, 0.57, 3346\",\n",
    "\"127, 130, 20, 8, 4, 1, 65, 0.40, 3334\",\n",
    "\"265, 270, 36, 10, 6, 3, 33, 1.20, 5853\",\n",
    "\"157, 163, 18, 8, 4, 2, 12, 1.13, 3982\",\n",
    "\"128, 135, 17, 9, 4, 1, 25, 0.52, 3374\",\n",
    "\"110, 120, 15, 8, 4, 2, 11, 0.59, 3119\",\n",
    "\"123, 130, 18, 8, 4, 2, 43, 0.39, 3268\",\n",
    "\"212, 230, 39, 12, 5, 3, 202, 4.29, 3648\",\n",
    "\"145, 145, 18, 8, 4, 2, 44, 0.22, 2783\",\n",
    "\"129, 135, 10, 6, 3, 1, 15, 1.00, 2438\",\n",
    "\"143, 145, 21, 7, 4, 2, 10, 1.20, 3529\",\n",
    "\"247, 252, 29, 9, 4, 2, 4, 1.25, 4626\",\n",
    "\"111, 120, 15, 8, 3, 1, 97, 1.11, 3205\",\n",
    "\"133, 145, 26, 7, 3, 1, 42, 0.36, 3059\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5869aa47-9bea-4933-a228-4f5f6ae39693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[633.4, 1008.25, 490.3333333333333, 1068.0, 903.25, 757.0, 782.75, 1289.5, 1140.4, 684.6666666666666, 1375.6666666666667, 481.6666666666667, 521.75, 704.5, 979.25, 555.0, 874.5, 1202.3333333333333, 1216.0, 890.25, 1170.25, 1772.0, 870.5, 784.0, 832.4, 946.25, 775.75, 840.75, 3048.0, 957.75, 1188.0, 1255.0, 840.25, 1316.6666666666667, 1018.3333333333334, 983.3333333333334, 1115.3333333333333, 833.5, 975.5, 995.5, 843.5, 779.75, 817.0, 729.6, 695.75, 812.6666666666666, 882.25, 1156.5, 1068.3333333333333, 1019.6666666666666]\n",
      "Total: 48882.549999999996\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"houses\").getOrCreate()\n",
    "\n",
    "def retrieve(string):\n",
    "    bed = string.split(\",\")[4]\n",
    "    tax = string.split(\",\")[8]\n",
    "    return int(tax) / int(bed)\n",
    "        \n",
    "\n",
    "masterRDD = spark.sparkContext.parallelize(data)\n",
    "ordd = masterRDD.map(lambda x: retrieve(x))\n",
    "print(ordd.collect())\n",
    "\n",
    "tasum = ordd.reduce(lambda x, y: x + y)\n",
    "print(f'Total: {tasum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09d348-1ed4-4d14-9028-a13565c57115",
   "metadata": {},
   "source": [
    "Exercise 3 Level: hard\n",
    "## Exercise 3 level: Hard\n",
    "Find the mean average of the taxes paid per house per number of beds. \n",
    "\n",
    "The answer should be something like this:\n",
    "(5.0, 4119.8), (4.0, 3927.3214285714284), (3.0, 3055.5), (6.0, 5853.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9ff41c-6953-4eee-9229-0b2b852bf03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 3167), (4, 4033), (3, 1471), (3, 3204), (4, 3613), (4, 3028), (4, 3131), (4, 5158), (5, 5702), (3, 2054), (3, 4127), (3, 1445), (4, 2087), (4, 2818), (4, 3917), (4, 2220), (4, 3498), (3, 3607), (3, 3648), (4, 3561), (4, 4681), (4, 7088), (4, 3482), (5, 3920), (5, 4162), (4, 3785), (4, 3103), (4, 3363), (4, 12192), (4, 3831), (3, 3564), (3, 3765), (4, 3361), (3, 3950), (3, 3055), (3, 2950), (3, 3346), (4, 3334), (6, 5853), (4, 3982), (4, 3374), (4, 3119), (4, 3268), (5, 3648), (4, 2783), (3, 2438), (4, 3529), (4, 4626), (3, 3205), (3, 3059)]\n",
      "[(4, 3927.3214285714284), (5, 4119.8), (6, 5853.0), (3, 3055.5)]\n"
     ]
    }
   ],
   "source": [
    "def to_list(a):\n",
    "    return [a]\n",
    "\n",
    "def append(a, b):\n",
    "    a.append(b)\n",
    "    return a\n",
    "\n",
    "def extend(a, b):\n",
    "    a.extend(b)\n",
    "    return a\n",
    "\n",
    "def avg(arr):\n",
    "    return sum(arr) / len(arr)\n",
    "\n",
    "rdd = masterRDD.map(lambda x: (int(x.split(\",\")[4]), int(x.split(\",\")[8])))\n",
    "print(rdd.collect())\n",
    "\n",
    "grprdd = rdd.combineByKey(to_list, append, extend)\n",
    "avgrdd = grprdd.map(lambda x: (x[0], avg(x[1])))\n",
    "print(avgrdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83afe5-c3e1-46d8-8d9d-0814daaab35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
